[
  {
    "slug": "llm-from-scratch-tokenization",
    "title": "Build LLM from scratch Part 1 (Tokenization)",
    "text": "# Theory behind Tokenization\r\n\r\nBefore a neural network can understand text, it needs to convert words into numbers. This is done through tokenization.\r\n## Why do we tokenize?\r\n - Computers can’t understand words directly — they need numerical representations.\r\n - Tokenization splits text into units (tokens) which are then mapped to IDs.\r\n\r\nThere are different approaches to tokenize text into numbers below are few approaches we will understand along with some pro's and con's in them:\r\n\r\n## Diffe",
    "tags": [
      "LLM",
      "GenAI",
      "Tokenizer"
    ],
    "category": "llm-from-scratch"
  }
]